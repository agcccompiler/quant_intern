# test_compressed_files.py
"""
æµ‹è¯•å‹ç¼©æ–‡ä»¶è¯»å–åŠŸèƒ½

éªŒè¯æ¡†æ¶æ˜¯å¦èƒ½æ­£ç¡®è¯»å–å„ç§æ ¼å¼çš„å‹ç¼©æ•°æ®æ–‡ä»¶
"""

import os
import sys
import pandas as pd
import numpy as np
import gzip
import lzma
import zipfile
from datetime import datetime

# è·¯å¾„è®¾ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºç¤ºä¾‹æ”¶ç›Šç‡æ•°æ®
    dates = pd.date_range('2023-01-01', periods=100, freq='D')
    stocks = ['000001', '000002', '000858', '600000', '600036']
    
    # ç”Ÿæˆéšæœºæ”¶ç›Šç‡æ•°æ®
    np.random.seed(42)
    data = np.random.randn(len(dates), len(stocks)) * 0.02
    
    df = pd.DataFrame(data, index=dates, columns=stocks)
    df.index.name = 'day_date'
    
    # é‡ç½®ç´¢å¼•ï¼Œä½¿day_dateæˆä¸ºä¸€åˆ—
    df_reset = df.reset_index()
    
    print(f"âœ“ æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ - å½¢çŠ¶: {df_reset.shape}")
    return df_reset

def save_in_formats(df, base_name="test_returns"):
    """ä¿å­˜ä¸ºä¸åŒæ ¼å¼çš„æ–‡ä»¶"""
    print("\nä¿å­˜ä¸ºä¸åŒæ ¼å¼...")
    
    data_dir = os.path.join(current_dir, "data")
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    files_created = {}
    
    # 1. æ ‡å‡†CSV
    csv_path = os.path.join(data_dir, f"{base_name}.csv")
    df.to_csv(csv_path, index=False)
    files_created['csv'] = csv_path
    print(f"âœ“ CSVæ–‡ä»¶: {csv_path}")
    
    # 2. GZå‹ç¼©
    gz_path = os.path.join(data_dir, f"{base_name}.csv.gz")
    df.to_csv(gz_path, index=False, compression='gzip')
    files_created['gz'] = gz_path
    print(f"âœ“ GZå‹ç¼©æ–‡ä»¶: {gz_path}")
    
    # 3. XZå‹ç¼©
    xz_path = os.path.join(data_dir, f"{base_name}.csv.xz")
    df.to_csv(xz_path, index=False, compression='xz')
    files_created['xz'] = xz_path
    print(f"âœ“ XZå‹ç¼©æ–‡ä»¶: {xz_path}")
    
    # 4. ZIPå‹ç¼©
    zip_path = os.path.join(data_dir, f"{base_name}.zip")
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        csv_content = df.to_csv(index=False)
        zipf.writestr(f"{base_name}.csv", csv_content)
    files_created['zip'] = zip_path
    print(f"âœ“ ZIPå‹ç¼©æ–‡ä»¶: {zip_path}")
    
    return files_created

def test_loading(files_created):
    """æµ‹è¯•åŠ è½½ä¸åŒæ ¼å¼çš„æ–‡ä»¶"""
    print("\næµ‹è¯•æ–‡ä»¶åŠ è½½...")
    
    try:
        from factor_backtest_framework import FactorBacktestPipeline
        
        # åˆ›å»ºæµæ°´çº¿å®ä¾‹
        pipeline = FactorBacktestPipeline()
        
        # æµ‹è¯•æ¯ç§æ ¼å¼
        results = {}
        for format_name, file_path in files_created.items():
            try:
                print(f"\næµ‹è¯• {format_name.upper()} æ ¼å¼: {file_path}")
                
                # ä½¿ç”¨æµæ°´çº¿çš„_load_data_fileæ–¹æ³•
                df_loaded = pipeline._load_data_file(file_path)
                
                print(f"  âœ“ åŠ è½½æˆåŠŸ - å½¢çŠ¶: {df_loaded.shape}")
                print(f"  âœ“ åˆ—å: {list(df_loaded.columns)}")
                print(f"  âœ“ æ•°æ®ç±»å‹: {df_loaded.dtypes.to_dict()}")
                
                # éªŒè¯æ•°æ®å†…å®¹
                if 'day_date' in df_loaded.columns:
                    print(f"  âœ“ æ—¥æœŸèŒƒå›´: {df_loaded['day_date'].min()} åˆ° {df_loaded['day_date'].max()}")
                
                results[format_name] = {
                    'success': True,
                    'shape': df_loaded.shape,
                    'columns': list(df_loaded.columns)
                }
                
            except Exception as e:
                print(f"  âœ— åŠ è½½å¤±è´¥: {str(e)}")
                results[format_name] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
        
    except ImportError as e:
        print(f"âœ— æ— æ³•å¯¼å…¥æ¡†æ¶: {str(e)}")
        return {}

def test_end_to_end(files_created):
    """ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½¿ç”¨å‹ç¼©æ–‡ä»¶è¿›è¡Œå› å­è¯„ä¼°"""
    print("\nç«¯åˆ°ç«¯æµ‹è¯•...")
    
    try:
        from factor_backtest_framework import FactorBacktestPipeline, FrameworkConfig
        
        # ä½¿ç”¨xzæ ¼å¼çš„æ–‡ä»¶è¿›è¡Œæµ‹è¯•
        xz_file = files_created.get('xz')
        if not xz_file:
            print("âœ— æœªæ‰¾åˆ°XZæµ‹è¯•æ–‡ä»¶")
            return False
        
        # åˆ›å»ºç®€å•çš„æµ‹è¯•å› å­æ•°æ®
        dates = pd.date_range('2023-01-01', periods=50, freq='D')
        stocks = ['000001', '000002', '000858', '600000', '600036']
        
        np.random.seed(123)
        factor_data = pd.DataFrame(
            np.random.randn(len(dates), len(stocks)) * 0.1,
            index=dates, columns=stocks
        )
        factor_data.index.name = 'day_date'
        
        # ä¿å­˜å› å­æ•°æ®
        factor_path = os.path.join(current_dir, "data", "test_factor.csv")
        factor_data.reset_index().to_csv(factor_path, index=False)
        
        # åˆ›å»ºé…ç½®
        config = FrameworkConfig.create(
            evaluation={'group_num': 5}
        )
        
        # åˆ›å»ºæµæ°´çº¿
        pipeline = FactorBacktestPipeline(config)
        
        # æ‰‹åŠ¨è®¾ç½®å› å­æ•°æ®
        pipeline.factor_data = factor_data
        
        # æµ‹è¯•è¯„ä¼°ï¼ˆä½¿ç”¨å‹ç¼©çš„æ”¶ç›Šç‡æ–‡ä»¶ï¼‰
        print(f"ä½¿ç”¨å‹ç¼©æ–‡ä»¶è¿›è¡Œè¯„ä¼°: {xz_file}")
        results = pipeline.evaluate_factor(return_file_path=xz_file)
        
        print("âœ“ ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸï¼")
        print(f"  ICIR: {results['ICIR']:.4f}")
        print(f"  å¹³å‡Rank IC: {results['average_rank_IC']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âœ— ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\næ¸…ç†æµ‹è¯•æ–‡ä»¶...")
    
    data_dir = os.path.join(current_dir, "data")
    if os.path.exists(data_dir):
        import shutil
        shutil.rmtree(data_dir)
        print("âœ“ æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å‹ç¼©æ–‡ä»¶æ”¯æŒåŠŸèƒ½æµ‹è¯•")
    print("="*60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    try:
        # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
        test_df = create_test_data()
        
        # 2. ä¿å­˜ä¸ºä¸åŒæ ¼å¼
        files_created = save_in_formats(test_df)
        
        # 3. æµ‹è¯•åŠ è½½
        load_results = test_loading(files_created)
        
        # 4. ç«¯åˆ°ç«¯æµ‹è¯•
        e2e_success = test_end_to_end(files_created)
        
        # 5. ç»Ÿè®¡ç»“æœ
        print("\n" + "="*60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*60)
        
        successful_formats = [fmt for fmt, result in load_results.items() if result.get('success', False)]
        failed_formats = [fmt for fmt, result in load_results.items() if not result.get('success', False)]
        
        print(f"âœ… æˆåŠŸæ”¯æŒçš„æ ¼å¼: {', '.join(successful_formats)}")
        if failed_formats:
            print(f"âŒ å¤±è´¥çš„æ ¼å¼: {', '.join(failed_formats)}")
        
        print(f"âœ… ç«¯åˆ°ç«¯æµ‹è¯•: {'é€šè¿‡' if e2e_success else 'å¤±è´¥'}")
        
        if len(successful_formats) >= 3 and e2e_success:
            print("\nğŸ‰ å‹ç¼©æ–‡ä»¶æ”¯æŒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
            print("æ¡†æ¶å·²æˆåŠŸæ”¯æŒä»¥ä¸‹å‹ç¼©æ ¼å¼:")
            print("â€¢ CSV (.csv)")
            print("â€¢ GZIPå‹ç¼© (.csv.gz)")
            print("â€¢ XZå‹ç¼© (.csv.xz)")
            print("â€¢ ZIPå‹ç¼© (.zip)")
            
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("1. GUIç•Œé¢ï¼šé€‰æ‹©æ–‡ä»¶æ—¶å¯ä»¥é€‰æ‹©å‹ç¼©æ ¼å¼")
            print("2. ç¼–ç¨‹æ¥å£ï¼šç›´æ¥ä¼ å…¥å‹ç¼©æ–‡ä»¶è·¯å¾„")
            print("3. å‘½ä»¤è¡Œï¼š--return-file your_data.csv.xz")
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä¾èµ–")
        
    except Exception as e:
        print(f"\nâœ— æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        try:
            cleanup_test_files()
        except:
            pass

if __name__ == "__main__":
    main() 