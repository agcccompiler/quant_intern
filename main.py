# main.py
"""
å› å­å›æµ‹æ¡†æ¶ä¸»æµæ°´çº¿

æ•´åˆå› å­ç”Ÿæˆã€å¹³æ»‘ã€è¯„ä¼°å’Œç»“æœç®¡ç†çš„å®Œæ•´æµç¨‹
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

try:
    from .config.config import FrameworkConfig, get_config
    from .core.factor_generator import FactorGenerator
    from .core.factor_evaluator import FactorEvaluator  
    from .core.factor_smoother import FactorSmoother
except ImportError:
    from factor_backtest_framework.config.config import FrameworkConfig, get_config
    from factor_backtest_framework.core.factor_generator import FactorGenerator
    from factor_backtest_framework.core.factor_evaluator import FactorEvaluator  
    from factor_backtest_framework.core.factor_smoother import FactorSmoother

class FactorBacktestPipeline:
    """å› å­å›æµ‹ä¸»æµæ°´çº¿"""
    
    def __init__(self, config: Optional[FrameworkConfig] = None):
        """
        åˆå§‹åŒ–æµæ°´çº¿
        
        Args:
            config: æ¡†æ¶é…ç½®
        """
        self.config = config or get_config()
        self.config.ensure_directories()
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [%(levelname)s] %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(self.config.output.log_dir, 'pipeline.log')),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.generator = FactorGenerator(self.config.dolphindb)
        self.evaluator = FactorEvaluator(self.config.evaluation)
        self.smoother = FactorSmoother(self.config.smoothing)
        
        # å­˜å‚¨æ•°æ®
        self.factor_data = None
        self.smoothed_data = None
        self.evaluation_results = None
        
        self.logger.info("å› å­å›æµ‹æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
    
    def _load_data_file(self, file_path: str) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§å‹ç¼©æ ¼å¼
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            DataFrame: åŠ è½½çš„æ•°æ®
        """
        import lzma
        import gzip
        import zipfile
        import io
        
        file_path = str(file_path)
        self.logger.info(f"æ£€æµ‹æ–‡ä»¶æ ¼å¼: {file_path}")
        
        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­å‹ç¼©æ ¼å¼
            if file_path.endswith('.xz'):
                self.logger.info("æ£€æµ‹åˆ°.xzå‹ç¼©æ ¼å¼")
                with lzma.open(file_path, 'rt', encoding='utf-8') as f:
                    df = pd.read_csv(f)
            elif file_path.endswith('.gz'):
                self.logger.info("æ£€æµ‹åˆ°.gzå‹ç¼©æ ¼å¼")
                with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                    df = pd.read_csv(f)
            elif file_path.endswith('.zip'):
                self.logger.info("æ£€æµ‹åˆ°.zipå‹ç¼©æ ¼å¼")
                with zipfile.ZipFile(file_path, 'r') as zip_file:
                    # è·å–zipæ–‡ä»¶ä¸­çš„ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶
                    csv_files = [name for name in zip_file.namelist() if name.endswith('.csv')]
                    if not csv_files:
                        raise ValueError("ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
                    csv_filename = csv_files[0]
                    self.logger.info(f"ä»ZIPæ–‡ä»¶ä¸­è¯»å–: {csv_filename}")
                    with zip_file.open(csv_filename) as f:
                        df = pd.read_csv(io.TextIOWrapper(f, encoding='utf-8'))
            elif file_path.endswith('.csv'):
                self.logger.info("æ£€æµ‹åˆ°æ ‡å‡†CSVæ ¼å¼")
                df = pd.read_csv(file_path)
            else:
                # å°è¯•ç›´æ¥è¯»å–ï¼Œè®©pandasè‡ªåŠ¨æ£€æµ‹
                self.logger.info("å°è¯•è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼")
                df = pd.read_csv(file_path)
            
            self.logger.info(f"æ•°æ®åŠ è½½æˆåŠŸ - å½¢çŠ¶: {df.shape}")
            return df
            
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
            # å°è¯•ä¸åŒçš„ç¼–ç 
            encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
            for encoding in encodings:
                try:
                    self.logger.info(f"å°è¯•ä½¿ç”¨ç¼–ç : {encoding}")
                    if file_path.endswith('.xz'):
                        with lzma.open(file_path, 'rt', encoding=encoding) as f:
                            df = pd.read_csv(f)
                    elif file_path.endswith('.gz'):
                        with gzip.open(file_path, 'rt', encoding=encoding) as f:
                            df = pd.read_csv(f)
                    else:
                        df = pd.read_csv(file_path, encoding=encoding)
                    
                    self.logger.info(f"ä½¿ç”¨ç¼–ç  {encoding} åŠ è½½æˆåŠŸ - å½¢çŠ¶: {df.shape}")
                    return df
                except:
                    continue
            
            raise ValueError(f"æ— æ³•åŠ è½½æ–‡ä»¶: {file_path}")
    
    def generate_factor(self, 
                       script_path: Optional[str] = None,
                       params: Optional[Dict[str, Any]] = None,
                       output_filename: Optional[str] = None) -> pd.DataFrame:
        """
        ç”Ÿæˆå› å­æ•°æ®
        
        Args:
            script_path: DolphinDBè„šæœ¬è·¯å¾„
            params: è„šæœ¬å‚æ•°
            output_filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å› å­DataFrame
        """
        if script_path is None:
            script_path = self.config.factor.script_path
        
        if params is None:
            params = {
                'start_date': self.config.factor.start_date,
                'end_date': self.config.factor.end_date,
                'start_time': self.config.factor.start_time,
                'end_time': self.config.factor.end_time,
                'seconds': self.config.factor.seconds,
                'portion': self.config.factor.portion,
                'job_id': f"{self.config.factor.job_id_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            }
        
        output_path = None
        if output_filename:
            output_path = os.path.join(self.config.factor.output_dir, output_filename)
        
        self.logger.info("å¼€å§‹ç”Ÿæˆå› å­æ•°æ®...")
        self.factor_data = self.generator.generate(script_path, params, output_path)
        
        return self.factor_data
    
    def smooth_factor(self, 
                     factor_df: Optional[pd.DataFrame] = None,
                     methods: Optional[Dict[str, Dict[str, Any]]] = None) -> pd.DataFrame:
        """
        å¹³æ»‘å› å­æ•°æ®
        
        Args:
            factor_df: å› å­æ•°æ®ï¼Œä¸æä¾›åˆ™ä½¿ç”¨å·²ç”Ÿæˆçš„æ•°æ®
            methods: å¹³æ»‘æ–¹æ³•é…ç½®
            
        Returns:
            å¹³æ»‘åçš„å› å­DataFrame
        """
        if factor_df is None:
            if self.factor_data is None:
                raise ValueError("æœªæ‰¾åˆ°å› å­æ•°æ®ï¼Œè¯·å…ˆç”Ÿæˆå› å­")
            factor_df = self.factor_data
        
        self.logger.info("å¼€å§‹å› å­å¹³æ»‘...")
        self.smoothed_data = self.smoother.smooth(factor_df, methods)
        
        return self.smoothed_data
    
    def evaluate_factor(self, 
                       factor_df: Optional[pd.DataFrame] = None,
                       returns_df: Optional[pd.DataFrame] = None,
                       return_file_path: Optional[str] = None) -> Dict[str, Any]:
        """
        è¯„ä¼°å› å­è¡¨ç°
        
        Args:
            factor_df: å› å­æ•°æ®ï¼Œä¸æä¾›åˆ™ä½¿ç”¨å¹³æ»‘åæˆ–åŸå§‹æ•°æ®
            returns_df: æ”¶ç›Šç‡æ•°æ®
            return_file_path: æ”¶ç›Šç‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        if factor_df is None:
            if self.smoothed_data is not None:
                factor_df = self.smoothed_data
            elif self.factor_data is not None:
                factor_df = self.factor_data
            else:
                raise ValueError("æœªæ‰¾åˆ°å› å­æ•°æ®")
        
        # å¦‚æœå› å­æ•°æ®æ˜¯é•¿æ ¼å¼ï¼Œè½¬æ¢ä¸ºå®½æ ¼å¼
        if 'code' in factor_df.columns and 'day_date' in factor_df.columns:
            factor_df = factor_df.pivot(index='day_date', columns='code', values='factor')
        
        # åŠ è½½æ”¶ç›Šç‡æ•°æ®
        if returns_df is None:
            if return_file_path is None:
                raise ValueError("å¿…é¡»æä¾›æ”¶ç›Šç‡æ•°æ®æˆ–æ–‡ä»¶è·¯å¾„")
            
            self.logger.info(f"åŠ è½½æ”¶ç›Šç‡æ•°æ®: {return_file_path}")
            returns_df = self._load_data_file(return_file_path)
            
            # ç¡®ä¿æ—¥æœŸåˆ—è®¾ç½®ä¸ºç´¢å¼•
            if 'day_date' in returns_df.columns:
                returns_df['day_date'] = pd.to_datetime(returns_df['day_date'])
                returns_df.set_index('day_date', inplace=True)
            elif returns_df.index.name != 'day_date':
                # å°è¯•å°†ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸç´¢å¼•
                returns_df.index = pd.to_datetime(returns_df.index)
                if returns_df.index.name is None:
                    returns_df.index.name = 'day_date'
        
        self.logger.info("å¼€å§‹å› å­è¯„ä¼°...")
        self.evaluation_results = self.evaluator.evaluate(factor_df, returns_df)
        
        return self.evaluation_results
    
    def create_visualization(self, 
                           evaluation_results: Optional[Dict[str, Any]] = None,
                           save_path: Optional[str] = None) -> plt.Figure:
        """
        åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        
        Args:
            evaluation_results: è¯„ä¼°ç»“æœï¼Œä¸æä¾›åˆ™ä½¿ç”¨å·²è®¡ç®—çš„ç»“æœ
            save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
            
        Returns:
            matplotlibå›¾å½¢å¯¹è±¡
        """
        if evaluation_results is None:
            if self.evaluation_results is None:
                raise ValueError("æœªæ‰¾åˆ°è¯„ä¼°ç»“æœï¼Œè¯·å…ˆè¿è¡Œå› å­è¯„ä¼°")
            evaluation_results = self.evaluation_results
        
        self.logger.info("åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        fig = self.evaluator.create_chart(evaluation_results)
        
        # ä¿å­˜å›¾ç‰‡
        if save_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            save_path = os.path.join(
                self.config.output.results_dir, 
                'figures', 
                f'factor_analysis_{timestamp}.{self.config.output.figure_format}'
            )
        
        fig.savefig(
            save_path, 
            format=self.config.output.figure_format,
            dpi=self.config.output.figure_dpi,
            bbox_inches='tight'
        )
        self.logger.info(f"å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        return fig
    
    def save_results(self, 
                    evaluation_results: Optional[Dict[str, Any]] = None,
                    include_factor_data: bool = True) -> Dict[str, str]:
        """
        ä¿å­˜æ‰€æœ‰ç»“æœ
        
        Args:
            evaluation_results: è¯„ä¼°ç»“æœ
            include_factor_data: æ˜¯å¦ä¿å­˜å› å­æ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        if evaluation_results is None:
            evaluation_results = self.evaluation_results
        
        if evaluation_results is None:
            raise ValueError("æœªæ‰¾åˆ°è¯„ä¼°ç»“æœ")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = {}
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_file = os.path.join(
            self.config.output.results_dir, 
            'data',
            f'evaluation_results_{timestamp}.csv'
        )
        
        # è½¬æ¢ä¸ºDataFrameä¿å­˜
        results_data = []
        for key, value in evaluation_results.items():
            if not isinstance(value, (pd.Series, pd.DataFrame, dict)):
                results_data.append({'metric': key, 'value': value})
        
        if results_data:
            results_df = pd.DataFrame(results_data)
            results_df.to_csv(results_file, index=False)
            saved_files['results'] = results_file
        
        # ä¿å­˜åˆ†ç»„æ”¶ç›Šç‡
        if 'group_returns' in evaluation_results:
            group_file = os.path.join(
                self.config.output.results_dir,
                'data', 
                f'group_returns_{timestamp}.csv'
            )
            group_df = pd.DataFrame({
                'group': range(1, len(evaluation_results['group_returns']) + 1),
                'return': evaluation_results['group_returns']
            })
            group_df.to_csv(group_file, index=False)
            saved_files['group_returns'] = group_file
        
        # ä¿å­˜æ—¶é—´åºåˆ—æ•°æ®
        if 'rank_ic_series' in evaluation_results:
            ic_file = os.path.join(
                self.config.output.results_dir,
                'data',
                f'ic_series_{timestamp}.csv'
            )
            ic_df = pd.DataFrame({
                'date': evaluation_results['rank_ic_series'].index,
                'rank_ic': evaluation_results['rank_ic_series'].values
            })
            ic_df.to_csv(ic_file, index=False)
            saved_files['ic_series'] = ic_file
        
        # ä¿å­˜å› å­æ•°æ®
        if include_factor_data:
            if self.smoothed_data is not None:
                smoothed_file = os.path.join(
                    self.config.output.results_dir,
                    'data',
                    f'smoothed_factor_{timestamp}.csv'
                )
                self.smoothed_data.to_csv(smoothed_file, index=False)
                saved_files['smoothed_factor'] = smoothed_file
            
            if self.factor_data is not None:
                factor_file = os.path.join(
                    self.config.output.results_dir,
                    'data',
                    f'raw_factor_{timestamp}.csv'
                )
                self.factor_data.to_csv(factor_file, index=False)
                saved_files['raw_factor'] = factor_file
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜ - æ–‡ä»¶æ•°: {len(saved_files)}")
        for file_type, file_path in saved_files.items():
            self.logger.info(f"  {file_type}: {file_path}")
        
        return saved_files
    
    def run_full_pipeline(self, 
                         return_file_path: str,
                         script_path: Optional[str] = None,
                         script_params: Optional[Dict[str, Any]] = None,
                         smoothing_methods: Optional[Dict[str, Dict[str, Any]]] = None,
                         save_results: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å›æµ‹æµæ°´çº¿
        
        Args:
            return_file_path: æ”¶ç›Šç‡æ–‡ä»¶è·¯å¾„
            script_path: DolphinDBè„šæœ¬è·¯å¾„
            script_params: è„šæœ¬å‚æ•°
            smoothing_methods: å¹³æ»‘æ–¹æ³•é…ç½®
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            å®Œæ•´çš„å›æµ‹ç»“æœ
        """
        self.logger.info("å¼€å§‹è¿è¡Œå®Œæ•´å›æµ‹æµæ°´çº¿...")
        
        try:
            # 1. ç”Ÿæˆå› å­
            factor_df = self.generate_factor(script_path, script_params)
            
            # 2. å¹³æ»‘å› å­
            if self.config.smoothing.enable:
                smoothed_df = self.smooth_factor(factor_df, smoothing_methods)
            else:
                smoothed_df = factor_df
            
            # 3. è¯„ä¼°å› å­
            evaluation_results = self.evaluate_factor(smoothed_df, return_file_path=return_file_path)
            
            # 4. åˆ›å»ºå¯è§†åŒ–
            fig = self.create_visualization(evaluation_results)
            
            # 5. ä¿å­˜ç»“æœ
            if save_results:
                saved_files = self.save_results(evaluation_results)
                evaluation_results['saved_files'] = saved_files
            
            # 6. æ±‡æ€»ç»“æœ
            pipeline_results = {
                'pipeline_config': self.config.to_dict(),
                'factor_data_shape': factor_df.shape if factor_df is not None else None,
                'smoothed_data_shape': smoothed_df.shape if smoothed_df is not None else None,
                'evaluation_results': evaluation_results,
                'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            self.logger.info("å®Œæ•´å›æµ‹æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
            return pipeline_results
            
        except Exception as e:
            self.logger.error(f"å›æµ‹æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿æ‰§è¡Œæ‘˜è¦"""
        summary = {
            'factor_data_available': self.factor_data is not None,
            'smoothed_data_available': self.smoothed_data is not None,
            'evaluation_completed': self.evaluation_results is not None
        }
        
        if self.factor_data is not None:
            summary['factor_data_shape'] = self.factor_data.shape
        
        if self.smoothed_data is not None:
            summary['smoothed_data_shape'] = self.smoothed_data.shape
        
        if self.evaluation_results is not None:
            summary['key_metrics'] = {
                'ICIR': self.evaluation_results.get('ICIR'),
                'average_rank_IC': self.evaluation_results.get('average_rank_IC'),
                'long_short_return': self.evaluation_results.get('long_short_return'),
                'excess_return': self.evaluation_results.get('excess_return')
            }
        
        return summary
    
    def batch_backtest(self, 
                      return_file_path: str,
                      script_path: Optional[str] = None,
                      script_params: Optional[Dict[str, Any]] = None,
                      parameter_combinations: Optional[List[Dict[str, Any]]] = None,
                      save_results: bool = True) -> Dict[str, Any]:
        """
        æ‰¹é‡å›æµ‹ï¼šå¯¹åŒä¸€å› å­æ•°æ®å°è¯•å¤šç§å‚æ•°ç»„åˆ
        
        Args:
            return_file_path: æ”¶ç›Šç‡æ–‡ä»¶è·¯å¾„
            script_path: DolphinDBè„šæœ¬è·¯å¾„
            script_params: DolphinDBè„šæœ¬å‚æ•°
            parameter_combinations: å‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«smoothingå’Œevaluationé…ç½®
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            æ‰¹é‡å›æµ‹ç»“æœå­—å…¸
        """
        self.logger.info("="*60)
        self.logger.info("å¼€å§‹æ‰¹é‡å›æµ‹")
        self.logger.info("="*60)
        
        # é»˜è®¤å‚æ•°ç»„åˆ
        if parameter_combinations is None:
            parameter_combinations = [
                {
                    'name': 'æ— å¹³æ»‘',
                    'smoothing': {'enable': False},
                    'evaluation': {'group_num': 10}
                },
                {
                    'name': '5æ—¥å‡å€¼',
                    'smoothing': {
                        'enable': True,
                        'methods': {'rolling_mean': {'window': 5}}
                    },
                    'evaluation': {'group_num': 10}
                },
                {
                    'name': '10æ—¥å‡å€¼',
                    'smoothing': {
                        'enable': True,
                        'methods': {'rolling_mean': {'window': 10}}
                    },
                    'evaluation': {'group_num': 10}
                },
                {
                    'name': '5æ—¥å‡å€¼+Z-score',
                    'smoothing': {
                        'enable': True,
                        'methods': {
                            'rolling_mean': {'window': 5},
                            'zscore': {'window': 20}
                        }
                    },
                    'evaluation': {'group_num': 10}
                },
                {
                    'name': 'EMAå¹³æ»‘',
                    'smoothing': {
                        'enable': True,
                        'methods': {'ema': {'alpha': 0.3}}
                    },
                    'evaluation': {'group_num': 10}
                }
            ]
        
        # ç”Ÿæˆå› å­æ•°æ®ï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
        if script_path is not None:
            self.logger.info("ç”ŸæˆåŸºç¡€å› å­æ•°æ®...")
            base_factor_df = self.generate_factor(script_path, script_params)
            if base_factor_df is None:
                raise ValueError("å› å­ç”Ÿæˆå¤±è´¥")
        else:
            # ä½¿ç”¨å·²æœ‰çš„å› å­æ•°æ®
            if self.factor_data is None:
                raise ValueError("æœªæä¾›è„šæœ¬è·¯å¾„ä¸”æ²¡æœ‰é¢„åŠ è½½çš„å› å­æ•°æ®")
            base_factor_df = self.factor_data.copy()
            self.logger.info(f"ä½¿ç”¨é¢„åŠ è½½çš„å› å­æ•°æ® - å½¢çŠ¶: {base_factor_df.shape}")
        
        # æ‰¹é‡å›æµ‹ç»“æœ
        batch_results = {
            'configurations': parameter_combinations,
            'results': [],
            'comparison_table': None,
            'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self.logger.info(f"å°†æµ‹è¯• {len(parameter_combinations)} ç§å‚æ•°ç»„åˆ")
        
        # å¯¹æ¯ç§å‚æ•°ç»„åˆè¿›è¡Œå›æµ‹
        for i, combo in enumerate(parameter_combinations, 1):
            combo_name = combo.get('name', f'ç»„åˆ{i}')
            self.logger.info(f"\n[{i}/{len(parameter_combinations)}] æµ‹è¯•ç»„åˆ: {combo_name}")
            
            try:
                # æ›´æ–°é…ç½®
                temp_config = self.config
                if 'smoothing' in combo:
                    # æ›´æ–°å¹³æ»‘é…ç½®
                    for key, value in combo['smoothing'].items():
                        setattr(temp_config.smoothing, key, value)
                
                if 'evaluation' in combo:
                    # æ›´æ–°è¯„ä¼°é…ç½®
                    for key, value in combo['evaluation'].items():
                        setattr(temp_config.evaluation, key, value)
                
                # é‡æ–°åˆå§‹åŒ–è¯„ä¼°å™¨å’Œå¹³æ»‘å™¨
                self.evaluator = FactorEvaluator(temp_config.evaluation)
                self.smoother = FactorSmoother(temp_config.smoothing)
                
                # åº”ç”¨å¹³æ»‘
                if temp_config.smoothing.enable:
                    smoothed_df = self.smoother.smooth(base_factor_df)
                else:
                    smoothed_df = base_factor_df.copy()
                
                # è¯„ä¼°å› å­ - éœ€è¦å…ˆåŠ è½½æ”¶ç›Šç‡æ•°æ®
                returns_df = self._load_data_file(return_file_path)
                if 'day_date' in returns_df.columns:
                    returns_df['day_date'] = pd.to_datetime(returns_df['day_date'])
                    returns_df.set_index('day_date', inplace=True)
                
                evaluation_results = self.evaluator.evaluate(smoothed_df, returns_df)
                
                # ä½¿ç”¨ç®€æ´æ—¥å¿—æ¨¡å¼
                self.evaluator._log_summary(evaluation_results, verbose=False)
                
                # ä¿å­˜ç»“æœ
                combo_result = {
                    'combination_name': combo_name,
                    'parameters': combo,
                    'metrics': {
                        'ICIR': evaluation_results['ICIR'],
                        'average_rank_IC': evaluation_results['average_rank_IC'],
                        'long_short_return': evaluation_results['long_short_return'],
                        'excess_return': evaluation_results['excess_return'],
                        'long_short_turnover': evaluation_results['long_short_turnover'],
                        'sharpe_ratio': evaluation_results.get('sharpe_ratio', 0.0),
                        'max_drawdown': evaluation_results.get('max_drawdown', 0.0)
                    },
                    'full_results': evaluation_results
                }
                
                batch_results['results'].append(combo_result)
                
            except Exception as e:
                self.logger.error(f"ç»„åˆ {combo_name} æµ‹è¯•å¤±è´¥: {str(e)}")
                combo_result = {
                    'combination_name': combo_name,
                    'parameters': combo,
                    'error': str(e)
                }
                batch_results['results'].append(combo_result)
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
        batch_results['comparison_table'] = self._create_comparison_table(batch_results['results'])
        
        # ä¿å­˜æ‰¹é‡ç»“æœ
        if save_results:
            saved_files = self._save_batch_results(batch_results)
            batch_results['saved_files'] = saved_files
        
        # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
        self._display_batch_summary(batch_results)
        
        return batch_results
    
    def _create_comparison_table(self, results: List[Dict[str, Any]]) -> pd.DataFrame:
        """åˆ›å»ºå‚æ•°ç»„åˆå¯¹æ¯”è¡¨æ ¼"""
        comparison_data = []
        
        for result in results:
            if 'error' not in result:
                metrics = result['metrics']
                row = {
                    'ç»„åˆåç§°': result['combination_name'],
                    'ICIR': f"{metrics['ICIR']:.4f}",
                    'å¹³å‡RankIC': f"{metrics['average_rank_IC']:.4f}",
                    'å¤šç©ºå¹´åŒ–æ”¶ç›Š': f"{metrics['long_short_return']:.4f}",
                    'è¶…é¢å¹´åŒ–æ”¶ç›Š': f"{metrics['excess_return']:.4f}",
                    'å¤šç©ºæ¢æ‰‹ç‡': f"{metrics['long_short_turnover']:.4f}",
                    'å¤æ™®æ¯”ç‡': f"{metrics['sharpe_ratio']:.4f}",
                    'æœ€å¤§å›æ’¤': f"{metrics['max_drawdown']:.4f}"
                }
                comparison_data.append(row)
            else:
                row = {
                    'ç»„åˆåç§°': result['combination_name'],
                    'ICIR': 'ERROR',
                    'å¹³å‡RankIC': 'ERROR',
                    'å¤šç©ºå¹´åŒ–æ”¶ç›Š': 'ERROR',
                    'è¶…é¢å¹´åŒ–æ”¶ç›Š': 'ERROR',
                    'å¤šç©ºæ¢æ‰‹ç‡': 'ERROR',
                    'å¤æ™®æ¯”ç‡': 'ERROR',
                    'æœ€å¤§å›æ’¤': 'ERROR'
                }
                comparison_data.append(row)
        
        return pd.DataFrame(comparison_data)
    
    def _save_batch_results(self, batch_results: Dict[str, Any]) -> Dict[str, str]:
        """ä¿å­˜æ‰¹é‡å›æµ‹ç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = {}
        
        # ä¿å­˜å¯¹æ¯”è¡¨æ ¼
        comparison_path = os.path.join(
            self.config.output.results_dir, 'data',
            f'batch_comparison_{timestamp}.csv'
        )
        batch_results['comparison_table'].to_csv(comparison_path, index=False, encoding='utf-8-sig')
        saved_files['comparison_table'] = comparison_path
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        import json
        detailed_path = os.path.join(
            self.config.output.results_dir, 'data',
            f'batch_detailed_{timestamp}.json'
        )
        
        # åºåˆ—åŒ–ç»“æœï¼ˆæ’é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼‰
        serializable_results = {
            'configurations': batch_results['configurations'],
            'execution_time': batch_results['execution_time'],
            'summary': []
        }
        
        for result in batch_results['results']:
            if 'error' not in result:
                summary_item = {
                    'combination_name': result['combination_name'],
                    'parameters': result['parameters'],
                    'metrics': result['metrics']
                }
                serializable_results['summary'].append(summary_item)
        
        with open(detailed_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        saved_files['detailed_results'] = detailed_path
        
        return saved_files
    
    def _display_batch_summary(self, batch_results: Dict[str, Any]):
        """æ˜¾ç¤ºæ‰¹é‡æµ‹è¯•æ±‡æ€»"""
        self.logger.info("\n" + "="*60)
        self.logger.info("æ‰¹é‡å›æµ‹ç»“æœæ±‡æ€»")
        self.logger.info("="*60)
        
        comparison_table = batch_results['comparison_table']
        
        # æ˜¾ç¤ºè¡¨æ ¼
        self.logger.info("\nå‚æ•°ç»„åˆå¯¹æ¯”:")
        for _, row in comparison_table.iterrows():
            self.logger.info(f"[{row['ç»„åˆåç§°']}] ICIR: {row['ICIR']} | RankIC: {row['å¹³å‡RankIC']} | "
                           f"å¤šç©ºæ”¶ç›Š: {row['å¤šç©ºå¹´åŒ–æ”¶ç›Š']} | è¶…é¢æ”¶ç›Š: {row['è¶…é¢å¹´åŒ–æ”¶ç›Š']}")
        
        # æ‰¾å‡ºæœ€ä½³ç»„åˆ
        valid_results = [r for r in batch_results['results'] if 'error' not in r]
        if valid_results:
            best_icir = max(valid_results, key=lambda x: x['metrics']['ICIR'])
            best_excess = max(valid_results, key=lambda x: x['metrics']['excess_return'])
            
            self.logger.info(f"\nğŸ† æœ€ä½³ICIRç»„åˆ: {best_icir['combination_name']} (ICIR: {best_icir['metrics']['ICIR']:.4f})")
            self.logger.info(f"ğŸ¯ æœ€ä½³è¶…é¢æ”¶ç›Šç»„åˆ: {best_excess['combination_name']} (è¶…é¢æ”¶ç›Š: {best_excess['metrics']['excess_return']:.4f})")
        
        self.logger.info("="*60)

def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å› å­å›æµ‹æ¡†æ¶')
    parser.add_argument('--return-file', required=True, 
                        help='æ”¶ç›Šç‡æ•°æ®æ–‡ä»¶è·¯å¾„ (æ”¯æŒ.csv, .csv.xz, .csv.gz, .zipç­‰æ ¼å¼)')
    parser.add_argument('--script-path', help='DolphinDBè„šæœ¬è·¯å¾„')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch', action='store_true', 
                        help='å¯ç”¨æ‰¹é‡å›æµ‹æ¨¡å¼ï¼Œæµ‹è¯•å¤šç§å‚æ•°ç»„åˆ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = get_config()
    if args.script_path:
        config.factor.script_path = args.script_path
    
    # åˆ›å»ºæµæ°´çº¿
    pipeline = FactorBacktestPipeline(config)
    
    if args.batch:
        # æ‰¹é‡å›æµ‹æ¨¡å¼
        print("="*60)
        print("å¯åŠ¨æ‰¹é‡å›æµ‹æ¨¡å¼")
        print("="*60)
        
        results = pipeline.batch_backtest(
            return_file_path=args.return_file,
            script_path=args.script_path
        )
        
        print("="*60)
        print("æ‰¹é‡å›æµ‹å®Œæˆï¼")
        print("="*60)
        
        # æ˜¾ç¤ºæœ€ä½³ç»“æœ
        valid_results = [r for r in results['results'] if 'error' not in r]
        if valid_results:
            best_result = max(valid_results, key=lambda x: x['metrics']['ICIR'])
            print(f"ğŸ† æœ€ä½³ç»„åˆ: {best_result['combination_name']}")
            print(f"   ICIR: {best_result['metrics']['ICIR']:.4f}")
            print(f"   è¶…é¢å¹´åŒ–æ”¶ç›Š: {best_result['metrics']['excess_return']:.4f}")
        
        if 'saved_files' in results:
            print("\nä¿å­˜çš„æ–‡ä»¶:")
            for file_type, file_path in results['saved_files'].items():
                print(f"  {file_type}: {file_path}")
    else:
        # å•æ¬¡å›æµ‹æ¨¡å¼
        results = pipeline.run_full_pipeline(args.return_file)
        
        print("="*60)
        print("å›æµ‹å®Œæˆï¼ä¸»è¦ç»“æœ:")
        print("="*60)
        
        eval_results = results['evaluation_results']
        print(f"ICIR: {eval_results['ICIR']:.4f}")
        print(f"å¹³å‡Rank IC: {eval_results['average_rank_IC']:.4f}")
        print(f"å¤šç©ºå¹´åŒ–æ”¶ç›Š: {eval_results['long_short_return']:.4f}")
        print(f"è¶…é¢å¹´åŒ–æ”¶ç›Š: {eval_results['excess_return']:.4f}")
        
        if 'saved_files' in eval_results:
            print("\nä¿å­˜çš„æ–‡ä»¶:")
            for file_type, file_path in eval_results['saved_files'].items():
                print(f"  {file_type}: {file_path}")

if __name__ == "__main__":
    main()
